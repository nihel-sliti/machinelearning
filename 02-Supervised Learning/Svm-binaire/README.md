# PrÃ©diction du diabÃ¨te avec SVM

## ğŸ“ Description
Ce projet vise Ã  **prÃ©dire si un patient est diabÃ©tique** en utilisant des **Support Vector Machines (SVM)**. Plusieurs noyaux ont Ã©tÃ© testÃ©s pour identifier celui offrant la meilleure performance.

## ğŸ“Š Noyaux testÃ©s
- **LinÃ©al** : Accuracy = 78.1%, AUC = 72.09%
- **RBF (Radial Basis Function)** : AUC = 66.5%
- **Polynomial** : AUC = 66.498108
- **SigmoÃ¯de**: AUC = 40.976952

## ğŸ”§ Ã‰tapes du projet
1. **PrÃ©paration des donnÃ©es** : Lecture du dataset et traitement des valeurs manquantes.
2. **Division en ensemble dâ€™entraÃ®nement et de test**.
3. **EntraÃ®nement de modÃ¨les SVM** avec diffÃ©rents noyaux.
4. **Ã‰valuation des performances** :
   - Matrice de confusion
   - Courbe ROC et AUC

## ğŸ› ï¸ Outils utilisÃ©s
- **Python** : Pandas, Scikit-learn, Matplotlib, Seaborn
- **ModÃ¨les SVM** : Noyaux linÃ©aire, RBF, polynomial et sigmoÃ¯de

## ğŸ“ˆ Visualisation de la matrice de confusion
![Confusion Matrix](image/matrice_de_confusion.png)

## ğŸ“‚ Structure du code
- `diabetes_svm_linear` : ModÃ¨le avec noyau linÃ©aire
- `diabetes_svm_rbf` : ModÃ¨le avec noyau RBF
- `diabetes_svm_poly` : ModÃ¨le avec noyau polynomial
- `diabetes_svm_sigmoid` : ModÃ¨le avec noyau sigmoÃ¯de

#  ModÃ¨les SVM avec diffÃ©rents noyaux
# .1 SVM avec noyau linÃ©aire
Objectif : Trouver un hyperplan qui sÃ©pare les deux classes avec une marge maximale.

Performance :

Accuracy : 78.1%
Precision, Recall et F1-score :
Classe 0 : Precision = 80%, Recall = 90%
Classe 1 : Precision = 73%, Recall = 54%
AUC (Area Under Curve) : 72.09%
Analyse :

Le modÃ¨le a une meilleure prÃ©cision sur la classe 0 que sur la classe 1.
Lâ€™AUC indique que le modÃ¨le a des performances raisonnables, mais peut Ãªtre amÃ©liorÃ©.
# .2 SVM avec noyau RBF (Radial Basis Function)
Objectif : GÃ©rer les relations non linÃ©aires entre les caractÃ©ristiques.
Performance :
AUC : 66.5%
Le noyau RBF nâ€™a pas surpassÃ© le noyau linÃ©aire ici. Cela suggÃ¨re que les relations entre les donnÃ©es pourraient Ãªtre plutÃ´t linÃ©aires.
# .3 SVM avec noyau polynomial
Objectif : Capturer les relations complexes entre les variables en utilisant des polynÃ´mes.
RÃ©sultat : La performance peut varier en fonction du degrÃ© du polynÃ´me utilisÃ©.
# .4 SVM avec noyau sigmoÃ¯de
Objectif : Capturer des relations non linÃ©aires semblables Ã  un rÃ©seau de neurones.
Performance : Ce noyau est moins courant et peut parfois sous-performer par rapport Ã  RBF ou linÃ©aire.
# Matrice de confusion et Ã©valuation des rÃ©sultats
Matrice de confusion :

TP (True Positive) : PrÃ©diction correcte que le patient est diabÃ©tique.
FP (False Positive) : Erreur, prÃ©dit diabÃ©tique alors que non.
FN (False Negative) : Erreur, patient rÃ©ellement diabÃ©tique mais non dÃ©tectÃ©.
TN (True Negative) : PrÃ©diction correcte de non-diabÃ©tique.
## InterprÃ©tation de lâ€™AUC et des courbes ROC
Courbe ROC : Montre la relation entre taux de vrais positifs (TPR) et taux de faux positifs (FPR).
AUC : Lâ€™AUC (Area Under Curve) permet de comparer les noyaux :
LinÃ©aire : 72.09%
RBF : 66.5%
Meilleure performance avec le noyau linÃ©aire dans ce cas.

## ğŸš€ RÃ©sultats et conclusion
Le **noyau linÃ©aire** a montrÃ© les meilleures performances, indiquant que les donnÃ©es ont une **relation plutÃ´t linÃ©aire**. Cependant, d'autres optimisations sont possibles avec une **normalisation** et **validation croisÃ©e**.

## ğŸ’¬ Feedback
N'hÃ©sitez pas Ã  ouvrir une **issue** ou Ã  me contacter pour toute suggestion d'amÃ©lioration !

---

