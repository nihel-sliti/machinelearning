# -*- coding: utf-8 -*-
"""Classification binaire.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15SB4rpyoBnCQiOazjyMHqyQC4lmdMX_w

# ***Classification binaire***
"""

import pandas as pd

db = pd.read_csv('/content/diabetes.csv')
db

db.info()

db.isnull().sum()

db.describe()

label = db['Outcome']
label

data =db.drop('Outcome', axis=1)
data

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(data,label,test_size=1/3, random_state=0) #splitting data with test size of 20%

"""# **1. Modèle avec noyau linéaire (kernel='linear')**"""

from sklearn import svm

model = svm.SVC(kernel='linear', C=1)

model.fit(x_train,y_train)

print(x_test)
print(y_test)

pred=model.predict(x_test)
print(pred)

from sklearn.metrics import accuracy_score
Acc = accuracy_score(y_test,pred)*100
print("Accuracy : %f" % (Acc))

"""recall ya3ni kadh jewb shih

**Precision :** proportion des prédictions correctes parmi toutes celles effectuées pour chaque classe.

**Recall (Rappel) :** proportion des échantillons correctement classés pour chaque classe parmi tous les échantillons pertinents de cette classe.

**F1-score :** moyenne harmonique de la précision et du rappel, donnant une mesure de l'équilibre entre les deux.

**Support :** nombre d'occurrences réelles de chaque classe dans les données testées.
"""

from sklearn.metrics import  classification_report
print(classification_report(y_test,pred))

"""Chaque ligne de la matrice représente les instances de la classe réelle, tandis que chaque colonne représente les instances prédites.

TP (True Positives) : cas où la classe est correctement prédite.

FP (False Positives) : cas où une classe est incorrectement prédite.

FN (False Negatives) : cas où une classe réelle n'est pas reconnue.

TN (True Negatives) : cas où une classe est correctement ignorée.
"""

from sklearn.metrics import confusion_matrix
CM= confusion_matrix(y_test,pred)
print(CM)

"""Visualizing Confusion Matrix using Heatmap"""

import numpy as np

import matplotlib.pyplot as plt

import seaborn as sns

class_names=[0,1] # name  of classes

fig, ax = plt.subplots()

tick_marks = np.arange(len(class_names))

plt.xticks(tick_marks, class_names)

plt.yticks(tick_marks, class_names)

# create heatmap

# CM1=pd.DataFrame(CM)

# print(CM1)

sns.heatmap(pd.DataFrame(CM), annot=True, cmap="YlGnBu" ,fmt='g')

ax.xaxis.set_label_position("top")

#plt.tight_layout()

plt.title('Confusion matrix', y=1.1)

plt.ylabel('Actual label')

plt.xlabel('Predicted label')

from sklearn.metrics import roc_curve, auc
fp, tp, thresholds = roc_curve(y_test, pred, pos_label=1)
print(fp)
print(tp)
roc_auc = auc(fp, tp)*100
print('AUC : %f' % roc_auc)

"""roc curve"""
import matplotlib.pyplot as plt
plt.plot(fp, tp, color='blue',label = 'AUC = %0.2f' %roc_auc)
plt.title('Receiver Operating Characteristic')
#plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % AUC)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

"""# **2. Modèle avec noyau RBF (kernel='rbf')**"""

# Créer un modèle SVM avec un noyau RBF (gaussien)
model_rbf = svm.SVC(kernel='rbf', C=1, gamma='scale')
model_rbf.fit(x_train, y_train)

# Prédiction et évaluation
y_pred_rbf = model_rbf.predict(x_test)
print("Classification Report (RBF Kernel):")
print(classification_report(y_test, y_pred_rbf))

# Matrice de confusion
print("Confusion Matrix (RBF Kernel):")
CM_rbf = confusion_matrix(y_test, y_pred_rbf)
print(CM_rbf)

# Visualisation de la matrice de confusion
plt.figure(figsize=(6,4))
sns.heatmap(pd.DataFrame(CM_rbf), annot=True, cmap="YlGnBu", fmt='g')
plt.title("Confusion Matrix (RBF Kernel)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

from sklearn.metrics import roc_curve, auc
fp, tp, thresholds = roc_curve(y_test,  y_pred_rbf, pos_label=1)
print(fp)
print(tp)
roc_auc = auc(fp, tp)*100
print('AUC : %f' % roc_auc)

"""roc curve"""
import matplotlib.pyplot as plt
plt.plot(fp, tp, color='blue',label = 'AUC = %0.2f' %roc_auc)
plt.title('Receiver Operating Characteristic')
#plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % AUC)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

"""# **3. Modèle avec noyau polynomial (kernel='poly')**"""

# Créer un modèle SVM avec un noyau polynomial
model_poly = svm.SVC(kernel='poly', degree=3, C=1)
model_poly.fit(x_train, y_train)

# Prédiction et évaluation
y_pred_poly = model_poly.predict(x_test)
print("Classification Report (Polynomial Kernel):")
print(classification_report(y_test, y_pred_poly))

# Matrice de confusion
print("Confusion Matrix (Polynomial Kernel):")
CM_poly = confusion_matrix(y_test, y_pred_poly)
print(CM_poly)

# Visualisation de la matrice de confusion
plt.figure(figsize=(6,4))
sns.heatmap(pd.DataFrame(CM_poly), annot=True, cmap="YlGnBu", fmt='g')
plt.title("Confusion Matrix (Polynomial Kernel)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()
from sklearn.metrics import roc_curve, auc
fp, tp, thresholds = roc_curve(y_test, y_pred_poly, pos_label=1)
print(fp)
print(tp)
roc_auc = auc(fp, tp)*100
print('AUC : %f' % roc_auc)

"""roc curve"""
import matplotlib.pyplot as plt
plt.plot(fp, tp, color='blue',label = 'AUC = %0.2f' %roc_auc)
plt.title('Receiver Operating Characteristic')
#plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % AUC)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

"""# **4. Modèle avec noyau sigmoïde (kernel='sigmoid')**"""

# Créer un modèle SVM avec un noyau sigmoïde
model_sigmoid = svm.SVC(kernel='sigmoid', C=1)
model_sigmoid.fit(x_train, y_train)

# Prédiction et évaluation
y_pred_sigmoid = model_sigmoid.predict(x_test)
print("Classification Report (Sigmoid Kernel):")
print(classification_report(y_test, y_pred_sigmoid))

# Matrice de confusion
print("Confusion Matrix (Sigmoid Kernel):")
CM_sigmoid = confusion_matrix(y_test, y_pred_sigmoid)
print(CM_sigmoid)

# Visualisation de la matrice de confusion
plt.figure(figsize=(6,4))
sns.heatmap(pd.DataFrame(CM_sigmoid), annot=True, cmap="YlGnBu", fmt='g')
plt.title("Confusion Matrix (Sigmoid Kernel)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()
from sklearn.metrics import roc_curve, auc
fp, tp, thresholds = roc_curve(y_test, y_pred_sigmoid, pos_label=1)
print(fp)
print(tp)
roc_auc = auc(fp, tp)*100
print('AUC : %f' % roc_auc)

"""roc curve"""
import matplotlib.pyplot as plt
plt.plot(fp, tp, color='blue',label = 'AUC = %0.2f' %roc_auc)
plt.title('Receiver Operating Characteristic')
#plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % AUC)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()